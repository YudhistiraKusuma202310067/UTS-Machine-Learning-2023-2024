# -*- coding: utf-8 -*-
"""UTS-MachineLearnig.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eZtq4ze5-8ZJqOxhznxwLSKyIpv65E9f
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Nama Kelompok - Machine Learning
- Yudhistira Kusuma 202310067
- Michael Mervin Ruswan 202310016
- Fajar Alfiantino 202310072
"""

# Loading the libraries
import numpy as np
import pandas as pd
from sklearn import datasets, tree
from sklearn.metrics import silhouette_score, confusion_matrix, classification_report, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.cluster import DBSCAN, KMeans, AgglomerativeClustering
from sklearn.neighbors import KNeighborsClassifier
from matplotlib import pyplot as plt

## Load Dataset from CSV
csv = '/content/drive/MyDrive/MachineLearning/UTS/mobileprice_modified.csv'
dataset = pd.read_csv(csv)

"""## Nomor 2 - Praproses Data

### Real Value
"""

# Tampilkan statistik deskriptif sebelum pengisian missing value dan standarisasi
# Statistik deskriptif => cabang dari statistik untuk mendeskripsikan dan merangkum data.
# 2 jenis statistik deskriptif => Measures of Central Tendency (mean, median, modus), Measures of Spread (std, kuartil)

deskripsi_awal = dataset.describe()
print("Statistik Deskriptif Sebelum Pengisian Missing Value dan Standarisasi:")
print(deskripsi_awal)

print(dataset.shape)

print(dataset)
dataset.isna().sum()

"""### Standard Scaler"""

# Pisahkan atribut prediktor dan atribut label
X = dataset.drop("price_range", axis=1)  # Atribut prediktor
y = dataset["price_range"]  # Atribut label

# Inisialisasi SimpleImputer menggunakan median sebagai strategi pengisian nilai
imputer = SimpleImputer(strategy="median")

# Inisialisasi StandardScaler untuk mengubah nilai atribut prediktor agar nilai
# dari masing-masing atribut seragam
scaler = StandardScaler()

# Imputasi missing value dan Lakukan standarisasi menggunakan StandardScaling Scaling pada atribut prediktor yang sudah diimputasi
X_imputed = imputer.fit_transform(X)
X_scaled = scaler.fit_transform(X_imputed)

# Konversi hasil transformasi kembali ke Pandas DataFrame (opsional)
X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)

# Gabungkan atribut prediktor yang sudah diimputasi dan distandarisasi dengan atribut label
data_scaled = pd.concat([X_scaled_df, y], axis=1)

# Tampilkan statistik deskriptif setelah pengisian missing value dan standarisasi
deskripsi_setelah = data_scaled.describe()
print("\nStatistik Deskriptif Setelah Pengisian Missing Value dan Standarisasi (Menggunakan StandardScaler):")
print(deskripsi_setelah)

"""### MinMax Scaler"""

# Pisahkan atribut prediktor
X = dataset.drop("price_range", axis=1)  # Atribut prediktor yang akan diimputasi

# Inisialisasi Min-Max Scaler dan Simple Imputer
scaler = MinMaxScaler()
imputer = SimpleImputer(strategy="median")

# Imputasi missing value dengan median
X_imputed = imputer.fit_transform(X)

# Lakukan standarisasi menggunakan Min-Max Scaling pada atribut prediktor yang sudah diimputasi
X_scaled = scaler.fit_transform(X_imputed)

# Konversi hasil transformasi kembali ke Pandas DataFrame (opsional)
X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)

# Gabungkan atribut prediktor yang sudah diimputasi dan distandarisasi dengan atribut label
data_scaled = pd.concat([X_scaled_df, y], axis=1)

# Tampilkan statistik deskriptif setelah pengisian dan standarisasi
deskripsi_setelah = data_scaled.describe()
print("Statistik Deskriptif Setelah Pengisian dan Standarisasi (Menggunakan MinMaxScaler):")
print(deskripsi_setelah)

"""## Nomor 3 - Classification

### Decision Tree
"""

# Pisahkan atribut prediktor dan atribut label
X = dataset.drop("price_range", axis=1)  # Atribut prediktor
y = dataset["price_range"]  # Atribut label

# Inisialisasi SimpleImputer untuk mengisi nilai-nilai yang hilang dengan median
imputer = SimpleImputer(strategy="median")
X = imputer.fit_transform(X)

# Bagi data menjadi data latih (80%) dan data uji (20%) dengan metode holdout
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inisialisasi model Decision Tree
decision_tree_model = DecisionTreeClassifier()

# Latih model Decision Tree menggunakan data latih
decision_tree_model.fit(X_train, y_train)

# Prediksi label pada data uji
y_pred = decision_tree_model.predict(X_test)

# Hitung akurasi
accuracy = accuracy_score(y_test, y_pred)
print("Akurasi Model: {:.2f}%".format(accuracy * 100))
class_report = classification_report(y_test, y_pred)

# Tampilkan confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)
print("Laporan Klasifikasi:\n", class_report)

"""### KNN"""

# Pisahkan atribut prediktor dan atribut label
X = dataset.drop("price_range", axis=1)  # Atribut prediktor
y = dataset["price_range"]  # Atribut label

# Inisialisasi SimpleImputer untuk mengisi nilai-nilai yang hilang dengan median
imputer = SimpleImputer(strategy="median")
X = imputer.fit_transform(X)

# Bagi data menjadi data latih (80%) dan data uji (20%) dengan metode holdout
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inisialisasi model KNN
knn_model = KNeighborsClassifier(n_neighbors=25)  # Ganti nilai n_neighbors sesuai kebutuhan, 25 terbaik, 94,75% (?)

# Latih model KNN menggunakan data latih
knn_model.fit(X_train, y_train)

# Prediksi label pada data uji
y_pred = knn_model.predict(X_test)

# Hitung akurasi
accuracy = accuracy_score(y_test, y_pred)
print("Akurasi Model: {:.2f}%".format(accuracy * 100))
class_report = classification_report(y_test, y_pred)

# Tampilkan confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)
print("Laporan Klasifikasi:\n", class_report)

"""### SVM"""

# Pisahkan atribut prediktor dan atribut label
X = dataset.drop("price_range", axis=1)  # Atribut prediktor yang sudah diimputasi dan distandarisasi
y = dataset["price_range"]  # Atribut label

# Inisialisasi SimpleImputer dan StandardScaler
imputer = SimpleImputer(strategy="median")
scaler = StandardScaler()

# Imputasi missing value dan standarisasi atribut prediktor
X_imputed = imputer.fit_transform(X)
X_scaled = scaler.fit_transform(X_imputed)

# Inisialisasi model SVM (Support Vector Machine) dengan kernel linear
svm_model = SVC(kernel='linear')

# Bagi data menjadi data latih (80%) dan data uji (20%) dengan metode holdout
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Latih model SVM menggunakan data latih
svm_model.fit(X_train, y_train)

# Prediksi label pada data uji
y_pred = svm_model.predict(X_test)

# Evaluasi model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

# Tampilkan hasil evaluasi
print("Akurasi: {:.2f}%".format(accuracy * 100))
print("Matriks Konfusi:\n", conf_matrix)
print("Laporan Klasifikasi:\n", class_report)

"""## Nomor 4 - Clustering

### Agglomerative Clustering
"""

# Pisahkan atribut prediktor
X = dataset.drop("price_range", axis=1)  # Atribut prediktor

# Inisialisasi SimpleImputer untuk mengisi nilai-nilai yang hilang dengan median
imputer = SimpleImputer(strategy="median")
X_imputed = imputer.fit_transform(X)

# Inisialisasi model Agglomerative Clustering
num_clusters_range = range(2,8)  # Ganti dengan jumlah cluster yang ingin dicoba
linkage_methods = ['ward', 'complete', 'average', 'single']  # Ganti dengan metode penggabungan yang ingin dicoba

best_silhouette_score = -1  # Inisialisasi skor Silhouette terbaik
best_config = None  # Inisialisasi konfigurasi terbaik

# Loop melalui variasi jumlah cluster dan metode penggabungan
for num_clusters in num_clusters_range:
    for linkage_method in linkage_methods:
        # Inisialisasi model Agglomerative Clustering
        agg_model = AgglomerativeClustering(n_clusters=num_clusters, linkage=linkage_method)

        # Lakukan klustering dengan Agglomerative Clustering
        labels = agg_model.fit_predict(X_imputed)

        # Hitung Silhouette Score
        silhouette_avg = silhouette_score(X_imputed, labels)

        # Cetak hasil
        print(f"Number of Clusters: {num_clusters}, Linkage Method: {linkage_method}, Silhouette Score: {silhouette_avg}")

        # Periksa apakah hasil saat ini lebih baik
        if silhouette_avg > best_silhouette_score:
            best_silhouette_score = silhouette_avg
            best_config = (num_clusters, linkage_method)

print("Best Configuration:")
print(f"Number of Clusters: {best_config[0]}, Linkage Method: {best_config[1]}")
print("Best Silhouette Score:", best_silhouette_score)

"""### DBScan"""

# Pisahkan atribut prediktor
X = dataset.drop("price_range", axis=1)  # Atribut prediktor

# Inisialisasi SimpleImputer untuk mengisi nilai-nilai yang hilang dengan median
imputer = SimpleImputer(strategy="median")
X_imputed = imputer.fit_transform(X)

# Inisialisasi StandardScaler untuk standarisasi atribut prediktor
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Range nilai eps dan min_samples yang ingin dicoba
eps_values = [4.0, 4.35, 4.5, 4.65]  # Ganti dengan nilai eps yang ingin dicoba
min_samples_values = [20, 30, 40, 50]  # Ganti dengan nilai min_samples yang ingin dicoba

best_silhouette_score = -1  # Inisialisasi skor Silhouette terbaik
best_eps = None  # Inisialisasi nilai eps terbaik
best_min_samples = None  # Inisialisasi nilai min_samples terbaik

for eps in eps_values:
    for min_samples in min_samples_values:
        # Inisialisasi model DBSCAN dengan parameter yang disesuaikan
        dbscan_model = DBSCAN(eps=eps, min_samples=min_samples)

        # Lakukan klustering dengan DBSCAN
        labels = dbscan_model.fit_predict(X_scaled)

        # Hitung Silhouette Score
        silhouette_avg = silhouette_score(X_scaled, labels)

        # Tampilkan hasil
        print(f"eps: {eps}, min_samples: {min_samples}, Silhouette Score: {silhouette_avg}")

        # Periksa apakah hasil saat ini lebih baik
        if silhouette_avg > best_silhouette_score:
            best_silhouette_score = silhouette_avg
            best_eps = eps
            best_min_samples = min_samples

print("Best Configuration:")
print(f"eps: {best_eps}, min_samples: {best_min_samples}")
print("Best Silhouette Score:", best_silhouette_score)

"""### K-Means"""

# Pisahkan atribut prediktor
X = dataset.drop("price_range", axis=1)  # Atribut prediktor

# Inisialisasi SimpleImputer untuk mengisi nilai-nilai yang hilang dengan median
imputer = SimpleImputer(strategy="median")
X_imputed = imputer.fit_transform(X)

# Range jumlah kluster yang ingin dicoba
num_clusters_range = range(2, 8)  # Coba dari 2 hingga 7 kluster

# Inisialisasi nilai n_init yang ingin digunakan
n_init_value = 10  # Ganti dengan nilai n_init yang Anda inginkan

best_silhouette_score = -1  # Inisialisasi skor Silhouette terbaik

for num_clusters in num_clusters_range:
    # Inisialisasi model K-Means dan setel n_init secara eksplisit
    kmeans_model = KMeans(n_clusters=num_clusters, n_init=n_init_value)

    # Lakukan klustering dengan K-Means
    labels = kmeans_model.fit_predict(X_imputed)

    # Hitung Silhouette Score
    silhouette_avg = silhouette_score(X_imputed, labels)

    # Tampilkan hasil
    print(f"Number of Clusters: {num_clusters}, Silhouette Score: {silhouette_avg}")

    # Periksa apakah hasil saat ini lebih baik
    if silhouette_avg > best_silhouette_score:
      best_silhouette_score = silhouette_avg
      best_config = num_clusters

print("Best Configuration:")
print(f"Number of Clusters: {best_config}")
print("Best Silhouette Score:", best_silhouette_score)